# Polygon Navigation System

Automatisches ROS2-System fÃ¼r Person-Tracking, Hand-Gestures und Navigation.

## ğŸš€ Quick Start

### Starte alle Nodes automatisch:

```bash
cd /home/user/ROS2/polygon_nav
./start_all_nodes.sh
```

Das Script:
1. âœ… Baut das Package mit `colcon build`
2. âœ… Sourced das Workspace
3. âœ… Startet automatisch alle Nodes aus `setup.py`
4. âœ… Zeigt Status aller laufenden Nodes

### Node Status checken:

```bash
./check_nodes.sh
```

### Alle Nodes stoppen:

```bash
./stop_all_nodes.sh
```

## ğŸ“‹ VerfÃ¼gbare Nodes

| Node | Start Command | Description |
|------|-------------|-------------|
| `yolo_processor` | `ros2 run polygon_nav yolo_processor` | YOLO Person Detection mit BYTETrack |
| `hand_gesture_detector` | `ros2 run polygon_nav hand_gesture_detector` | MediaPipe Hand-Tracking |
| `person_tracker` | `ros2 run polygon_nav person_tracker` | Person Position Tracking |
| `sensor_fusion` | `ros2 run polygon_nav sensor_fusion` | Sensor Fusion (Follow/Sit Detection) |
| `state_machine` | `ros2 run polygon_nav state_machine` | State Machine (SIT/FOLLOW) |
| `polygon_explorer` | `ros2 run polygon_nav polygon_explorer` | Navigation Client |

## ğŸ”„ Workflow

```
Camera Stream
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DETECTION LAYER                â”‚
â”‚ â€¢ yolo_processor               â”‚
â”‚ â€¢ hand_gesture_detector        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SENSOR FUSION                  â”‚
â”‚ â€¢ sensor_fusion                â”‚
â”‚   â†’ action_id: "follow"/"sit" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STATE MACHINE                  â”‚
â”‚ â€¢ state_machine                â”‚
â”‚   â†’ State: SIT or FOLLOW       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Topics

### Input Topics (External)
- `/image` (Camera Stream)
- `/odom` (Robot Odometry)
- `/scan` (LiDAR Scan)

### Internal Topics
- `/yolo/detections` - Person Detections
- `/yolo/processed_image` - YOLO Visual
- `/hand/pointer_finger` - Hand Gesture Position
- `/hand/annotated_image` - Hand Visual
- `/fusion_out` - Fused Data
- `/state_machine_out` - State Machine Output
- `/person_position` - World Position of Persons

## ğŸ”§ Manual Start (Advanced)

Wenn Sie Nodes einzeln starten mÃ¶chten:

```bash
# Terminal 1: YOLO
ros2 run polygon_nav yolo_processor

# Terminal 2: Hand Gesture
ros2 run polygon_nav hand_gesture_detector

# Terminal 3: Person Tracker
ros2 run polygon_nav person_tracker

# Terminal 4: Sensor Fusion
ros2 run polygon_nav sensor_fusion --ros-args -p action_id:=0

# Terminal 5: State Machine
ros2 run polygon_nav state_machine --ros-args -p debug:=true
```

## ğŸ“ Logs

Node-Logs werden in `/tmp/<node_name>.log` gespeichert:

```bash
# Logs ansehen
tail -f /tmp/yolo_processor.log
tail -f /tmp/hand_gesture_detector.log
```

## ğŸ¯ Use Cases

### Follow a Person
1. System erkennt Personen (YOLO)
2. User zeigt auf Person (Hand Gesture)
3. Sensor Fusion â†’ `action_id="follow"`
4. State Machine â†’ State = FOLLOW
5. Robot folgt der Person

### Sit/Stop
1. User zeigt weg â†’ `action_id="default"`
2. State Machine â†’ State = SIT
3. Robot bleibt stehen

## ğŸ“¸ Visualization

RViz2 Start:
```bash
ros2 run rviz2 rviz2
```

Display Topics:
- `/yolo/processed_image` - YOLO Detections
- `/hand/annotated_image` - Hand Tracking
- `/person_position` - Person Position Marker

